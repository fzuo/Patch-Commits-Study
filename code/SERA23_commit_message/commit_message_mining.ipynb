{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bd904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:45:40.776970: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-07 15:45:40.794915: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-07 15:45:40.794930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-07 15:45:40.795508: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-07 15:45:40.798636: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-07 15:45:40.798982: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-07 15:45:41.248901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import copy\n",
    "import subprocess\n",
    "import bisect\n",
    "import shutil\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from os.path import expanduser\n",
    "from filecmp import dircmp\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "tf.random.set_seed(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "552f3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4621, 50)\n",
      "(4621, 100)\n",
      "4621\n"
     ]
    }
   ],
   "source": [
    "with open('sec_patch_commit_dict.pkl','rb') as handler:\n",
    "    adv_dict = pickle.load(handler)\n",
    "\n",
    "with open('non_patch_commit_dict.pkl','rb') as handler:\n",
    "    ben_dict = pickle.load(handler)\n",
    "    \n",
    "w2v_model_50 = gensim.models.Word2Vec.load(\"patch_commit_voc50_mc5.w2v\")\n",
    "w2v_model_100= gensim.models.Word2Vec.load(\"patch_commit_voc100_mc5.w2v\")\n",
    "\n",
    "print(w2v_model_50.wv.vectors.shape)\n",
    "print(w2v_model_100.wv.vectors.shape)\n",
    "\n",
    "vocab_size = len(w2v_model_50.wv.key_to_index)\n",
    "print(vocab_size)\n",
    "maxlen = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533135b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_txt_matrix(my_dict, word2vecs, max_len):\n",
    "    \n",
    "    row = 0\n",
    "    text_matrix = np.zeros((len(my_dict), max_len), dtype = np.int32)\n",
    "    filter_out = []\n",
    "    for key, value in my_dict.items():\n",
    "        \n",
    "        col = 0\n",
    "        list_of_word = value[0]\n",
    "        # print(key)\n",
    "        # print(\"===================\")\n",
    "        # print(list_of_word)\n",
    "        \n",
    "        for word in list_of_word:\n",
    "            if col >= max_len:\n",
    "                break\n",
    "                \n",
    "            if word in word2vecs.key_to_index.keys():\n",
    "                # print(word)\n",
    "                # print(word2vecs.key_to_index[word])\n",
    "                text_matrix[row][col] = word2vecs.key_to_index[word]\n",
    "                col += 1\n",
    "        \n",
    "        if value[1] and col < max_len-1:\n",
    "            \n",
    "            if text_matrix[row][col-1] != 0:\n",
    "                text_matrix[row][col] = word2vecs.key_to_index[\".\"]\n",
    "                col += 1\n",
    "            \n",
    "            list_of_word = value[1]\n",
    "            # print(list_of_word)\n",
    "            for word in list_of_word:\n",
    "                if col >= max_len:\n",
    "                    break\n",
    "                \n",
    "                if word in word2vecs.key_to_index.keys():\n",
    "                    # print(word)\n",
    "                    # print(word2vecs.key_to_index[word])\n",
    "                    text_matrix[row][col] = word2vecs.key_to_index[word]\n",
    "                    col += 1\n",
    "        #print (col)\n",
    "        if col<6:\n",
    "            filter_out.append(row)\n",
    "            #print(row)\n",
    "                    \n",
    "        row+=1\n",
    "        #if row>2:\n",
    "        #    break\n",
    "    #print(len(filter_out))        \n",
    "    return np.delete(text_matrix , filter_out,  0)\n",
    "    \n",
    "\n",
    "adv_matrix = generate_txt_matrix(adv_dict, w2v_model_50.wv, 200)\n",
    "ben_matrix = generate_txt_matrix(ben_dict, w2v_model_50.wv, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a52c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5603, 200)\n",
      "(623, 200)\n",
      "(5603,)\n",
      "(623,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.vstack((adv_matrix[:2239], ben_matrix[:3364]))\n",
    "x_val =  np.vstack((adv_matrix[2239:], ben_matrix[3364:]))\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "\n",
    "y_train = np.hstack((np.ones(2239), np.zeros(3364)))\n",
    "y_val = np.hstack((np.ones(adv_matrix.shape[0] - 2239), np.zeros(ben_matrix.shape[0] - 3364)))\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4a7011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 200)\n",
      "(623,)\n"
     ]
    }
   ],
   "source": [
    "training_data = np.hstack((x_train, y_train.reshape(-1,1)))\n",
    "np.random.shuffle(training_data)\n",
    "x_train = training_data[:, :-1]\n",
    "y_train = training_data[:, -1]\n",
    "\n",
    "training_data = np.hstack((x_val, y_val.reshape(-1,1)))\n",
    "np.random.shuffle(training_data)\n",
    "x_val = training_data[:, :-1]\n",
    "y_val = training_data[:, -1]\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7fcddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    " \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)  # self-attention layer\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # layer norm\n",
    "        ffn_output = self.ffn(out1)  #feed-forward layer\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)  # layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c05d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, weights=[w2v_model_50.wv.vectors], output_dim=embed_dim, trainable=False)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10cd70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:45:57.958567: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 50  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e74eab-df74-4380-b029-395678723b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"tf_model_{epoch:02d}-accuracy{accuracy:.2f}.h5\"\n",
    "\n",
    "checkpoint=ModelCheckpoint(\n",
    "        filepath=filepath,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, validation_data=(x_val, y_val), epochs=60, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca8206e-c0b2-4a06-9ae9-3ea4cafaedf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2868306636810303\n",
      "Test accuracy: 0.9165329337120056\n"
     ]
    }
   ],
   "source": [
    "## Load a pre-trained model\n",
    "model.load_weights(\"model_49-accuracy0.92.h5\")\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose = 0) \n",
    " \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2762afbc-b40e-47bd-8ec6-d683a3aac5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 20ms/step\n",
      "predictions shape: (623,)\n",
      "Precision: 0.930\n",
      "Recall: 0.855\n",
      "F1_score: 0.891\n",
      "Accuracy: 0.917\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(x_val), axis=1)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_val, predictions))\n",
    "print('Recall: %.3f' % recall_score(y_val, predictions))\n",
    "print('F1_score: %.3f' % f1_score(y_val, predictions))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2c249-6afc-4546-bd93-d6961399004d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
